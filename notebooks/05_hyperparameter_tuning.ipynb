{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning and Feature Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "\n",
    "In this notebook, we tune the hyperparameters of the top-performing model LightGBM using Optuna. Our objective is to improve AUC-ROC scores beyond the default settings by finding the optimal configuration of model parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup and Data Preparation\n",
    "\n",
    "In this section, we import all required libraries and prepare the dataset for hyperparameter tuning. We use a preprocessed version of the dataset and split it into training and testing sets using stratified sampling to preserve class distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries and General Setup For LightGBM Tuning\n",
    "import optuna\n",
    "import shap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from lightgbm import early_stopping, log_evaluation, LGBMClassifier\n",
    "\n",
    "df = pd.read_csv(\"data/train_preprocessed.csv\")\n",
    "\n",
    "X = df.drop(columns=[\"loan_status\", \"id\"])  \n",
    "y = df[\"loan_status\"]\n",
    "\n",
    "X_train_lgbm, X_test_lgbm, y_train_lgbm, y_test_lgbm = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Objective Function (Optuna)\n",
    "\n",
    "We use Optuna to define and optimize our objective function for the LightGBM model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM Objective Function\n",
    "def objective_lgbm(trial):\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"verbosity\": -1,\n",
    "        \"random_state\": 42,\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 7),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 15, 63),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.7, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.7, 1.0),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 100),\n",
    "    }\n",
    "\n",
    "    model = LGBMClassifier(**params)\n",
    "    model.fit(\n",
    "    X_train_lgbm, y_train_lgbm,\n",
    "    eval_set=[(X_test_lgbm, y_test_lgbm)],\n",
    "    eval_metric=\"auc\",\n",
    "    callbacks=[\n",
    "        early_stopping(20, verbose=False),\n",
    "        log_evaluation(0)  \n",
    "    ]\n",
    ")\n",
    "    preds = model.predict_proba(X_test_lgbm)[:, 1]\n",
    "    return roc_auc_score(y_test_lgbm, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Optimization\n",
    "\n",
    "\n",
    "We run the Optuna study for a limited number of trials and extract the best-performing configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 15:38:03,626] A new study created in memory with name: no-name-7ac0e5d1-4b24-433c-9f57-42d97948cdc8\n",
      "[I 2025-05-17 15:38:04,754] Trial 0 finished with value: 0.9484406671298025 and parameters: {'n_estimators': 287, 'learning_rate': 0.01598214157606596, 'max_depth': 6, 'num_leaves': 25, 'subsample': 0.8843848878734599, 'colsample_bytree': 0.8711903558755092, 'min_child_samples': 25}. Best is trial 0 with value: 0.9484406671298025.\n",
      "[I 2025-05-17 15:38:05,877] Trial 1 finished with value: 0.9592515535585554 and parameters: {'n_estimators': 476, 'learning_rate': 0.05584296095691592, 'max_depth': 6, 'num_leaves': 23, 'subsample': 0.9096913966991582, 'colsample_bytree': 0.7066660314251398, 'min_child_samples': 39}. Best is trial 1 with value: 0.9592515535585554.\n",
      "[I 2025-05-17 15:38:06,533] Trial 2 finished with value: 0.9552263799272912 and parameters: {'n_estimators': 125, 'learning_rate': 0.07261673659954494, 'max_depth': 6, 'num_leaves': 40, 'subsample': 0.8171605616693548, 'colsample_bytree': 0.9475733015820557, 'min_child_samples': 62}. Best is trial 1 with value: 0.9592515535585554.\n",
      "[I 2025-05-17 15:38:06,987] Trial 3 finished with value: 0.9547500882517697 and parameters: {'n_estimators': 192, 'learning_rate': 0.08162486104711185, 'max_depth': 4, 'num_leaves': 51, 'subsample': 0.8960224370100669, 'colsample_bytree': 0.9871364077968013, 'min_child_samples': 85}. Best is trial 1 with value: 0.9592515535585554.\n",
      "[I 2025-05-17 15:38:07,342] Trial 4 finished with value: 0.9422341121514799 and parameters: {'n_estimators': 141, 'learning_rate': 0.03711069508416897, 'max_depth': 4, 'num_leaves': 28, 'subsample': 0.9471525693522359, 'colsample_bytree': 0.8199127090022882, 'min_child_samples': 87}. Best is trial 1 with value: 0.9592515535585554.\n",
      "[I 2025-05-17 15:38:08,006] Trial 5 finished with value: 0.9562404865187609 and parameters: {'n_estimators': 294, 'learning_rate': 0.0589467498560543, 'max_depth': 7, 'num_leaves': 18, 'subsample': 0.9443981719800725, 'colsample_bytree': 0.7433192084879138, 'min_child_samples': 38}. Best is trial 1 with value: 0.9592515535585554.\n",
      "[I 2025-05-17 15:38:09,092] Trial 6 finished with value: 0.9591976500324731 and parameters: {'n_estimators': 451, 'learning_rate': 0.059024486616676614, 'max_depth': 6, 'num_leaves': 16, 'subsample': 0.9958660778342759, 'colsample_bytree': 0.7071645147064233, 'min_child_samples': 59}. Best is trial 1 with value: 0.9592515535585554.\n",
      "[I 2025-05-17 15:38:09,652] Trial 7 finished with value: 0.9456921825897862 and parameters: {'n_estimators': 101, 'learning_rate': 0.030601796845117, 'max_depth': 7, 'num_leaves': 41, 'subsample': 0.9814778077035596, 'colsample_bytree': 0.7962746750225783, 'min_child_samples': 49}. Best is trial 1 with value: 0.9592515535585554.\n",
      "[I 2025-05-17 15:38:11,330] Trial 8 finished with value: 0.9580001047710722 and parameters: {'n_estimators': 491, 'learning_rate': 0.03739084365671443, 'max_depth': 5, 'num_leaves': 40, 'subsample': 0.892830694271614, 'colsample_bytree': 0.8834386276316801, 'min_child_samples': 25}. Best is trial 1 with value: 0.9592515535585554.\n",
      "[I 2025-05-17 15:38:12,363] Trial 9 finished with value: 0.9587339487443247 and parameters: {'n_estimators': 496, 'learning_rate': 0.08125581748752587, 'max_depth': 7, 'num_leaves': 52, 'subsample': 0.7171706495902667, 'colsample_bytree': 0.7121802744917795, 'min_child_samples': 54}. Best is trial 1 with value: 0.9592515535585554.\n",
      "[I 2025-05-17 15:38:12,964] Trial 10 finished with value: 0.9579366170730416 and parameters: {'n_estimators': 390, 'learning_rate': 0.09910510016331034, 'max_depth': 3, 'num_leaves': 62, 'subsample': 0.7949718876353866, 'colsample_bytree': 0.7782316432558489, 'min_child_samples': 100}. Best is trial 1 with value: 0.9592515535585554.\n",
      "[I 2025-05-17 15:38:13,796] Trial 11 finished with value: 0.9576481394502971 and parameters: {'n_estimators': 404, 'learning_rate': 0.05710192715631727, 'max_depth': 6, 'num_leaves': 15, 'subsample': 0.978058281932607, 'colsample_bytree': 0.706881166376327, 'min_child_samples': 10}. Best is trial 1 with value: 0.9592515535585554.\n",
      "[I 2025-05-17 15:38:15,061] Trial 12 finished with value: 0.9586765330061618 and parameters: {'n_estimators': 419, 'learning_rate': 0.050250314448502725, 'max_depth': 5, 'num_leaves': 27, 'subsample': 0.9988532396581606, 'colsample_bytree': 0.7553749293814369, 'min_child_samples': 68}. Best is trial 1 with value: 0.9592515535585554.\n",
      "[I 2025-05-17 15:38:15,862] Trial 13 finished with value: 0.95886184684017 and parameters: {'n_estimators': 441, 'learning_rate': 0.06865261782457817, 'max_depth': 6, 'num_leaves': 21, 'subsample': 0.9348932396545658, 'colsample_bytree': 0.8314777681336604, 'min_child_samples': 43}. Best is trial 1 with value: 0.9592515535585554.\n",
      "[I 2025-05-17 15:38:16,982] Trial 14 finished with value: 0.9581068105363981 and parameters: {'n_estimators': 350, 'learning_rate': 0.04897598575326286, 'max_depth': 5, 'num_leaves': 32, 'subsample': 0.8485067706579885, 'colsample_bytree': 0.7066716821056319, 'min_child_samples': 72}. Best is trial 1 with value: 0.9592515535585554.\n",
      "[I 2025-05-17 15:38:17,863] Trial 15 finished with value: 0.9579014056587093 and parameters: {'n_estimators': 345, 'learning_rate': 0.06725682803425055, 'max_depth': 6, 'num_leaves': 33, 'subsample': 0.7459666986455202, 'colsample_bytree': 0.7528372318292323, 'min_child_samples': 32}. Best is trial 1 with value: 0.9592515535585554.\n",
      "[I 2025-05-17 15:38:18,945] Trial 16 finished with value: 0.9423701954873432 and parameters: {'n_estimators': 452, 'learning_rate': 0.012279613732776716, 'max_depth': 4, 'num_leaves': 21, 'subsample': 0.9197966435527615, 'colsample_bytree': 0.9132396301772375, 'min_child_samples': 57}. Best is trial 1 with value: 0.9592515535585554.\n",
      "[I 2025-05-17 15:38:19,611] Trial 17 finished with value: 0.9546290955220487 and parameters: {'n_estimators': 224, 'learning_rate': 0.045166210304862106, 'max_depth': 7, 'num_leaves': 16, 'subsample': 0.8501175991607984, 'colsample_bytree': 0.7928482631115422, 'min_child_samples': 76}. Best is trial 1 with value: 0.9592515535585554.\n",
      "[I 2025-05-17 15:38:20,677] Trial 18 finished with value: 0.9592878662597263 and parameters: {'n_estimators': 348, 'learning_rate': 0.0898848883003158, 'max_depth': 5, 'num_leaves': 23, 'subsample': 0.9663638365839305, 'colsample_bytree': 0.7400773536571739, 'min_child_samples': 16}. Best is trial 18 with value: 0.9592878662597263.\n",
      "[I 2025-05-17 15:38:21,211] Trial 19 finished with value: 0.9567913085252102 and parameters: {'n_estimators': 345, 'learning_rate': 0.0978933516044634, 'max_depth': 3, 'num_leaves': 34, 'subsample': 0.9599948249682153, 'colsample_bytree': 0.7419920214089492, 'min_child_samples': 14}. Best is trial 18 with value: 0.9592878662597263.\n",
      "[I 2025-05-17 15:38:22,080] Trial 20 finished with value: 0.958437404939599 and parameters: {'n_estimators': 251, 'learning_rate': 0.08703644489658538, 'max_depth': 5, 'num_leaves': 46, 'subsample': 0.9173782774225226, 'colsample_bytree': 0.7682385874102541, 'min_child_samples': 20}. Best is trial 18 with value: 0.9592878662597263.\n",
      "[I 2025-05-17 15:38:22,974] Trial 21 finished with value: 0.957967899572165 and parameters: {'n_estimators': 466, 'learning_rate': 0.06293498178061199, 'max_depth': 6, 'num_leaves': 23, 'subsample': 0.9947137702276192, 'colsample_bytree': 0.7301535489485524, 'min_child_samples': 37}. Best is trial 18 with value: 0.9592878662597263.\n",
      "[I 2025-05-17 15:38:24,016] Trial 22 finished with value: 0.95937876707069 and parameters: {'n_estimators': 378, 'learning_rate': 0.0773829408893851, 'max_depth': 5, 'num_leaves': 19, 'subsample': 0.964242680214378, 'colsample_bytree': 0.7251481370176671, 'min_child_samples': 29}. Best is trial 22 with value: 0.95937876707069.\n",
      "[I 2025-05-17 15:38:24,853] Trial 23 finished with value: 0.959124399575439 and parameters: {'n_estimators': 374, 'learning_rate': 0.08979442827524656, 'max_depth': 4, 'num_leaves': 28, 'subsample': 0.9640502379986408, 'colsample_bytree': 0.7331837127618654, 'min_child_samples': 30}. Best is trial 22 with value: 0.95937876707069.\n",
      "[I 2025-05-17 15:38:25,744] Trial 24 finished with value: 0.9588042525149523 and parameters: {'n_estimators': 309, 'learning_rate': 0.07587936332823388, 'max_depth': 5, 'num_leaves': 20, 'subsample': 0.9153070979779234, 'colsample_bytree': 0.8052067995311805, 'min_child_samples': 20}. Best is trial 22 with value: 0.95937876707069.\n",
      "[I 2025-05-17 15:38:26,436] Trial 25 finished with value: 0.9582093790349513 and parameters: {'n_estimators': 322, 'learning_rate': 0.08958966420415074, 'max_depth': 5, 'num_leaves': 32, 'subsample': 0.8740644993677134, 'colsample_bytree': 0.7776200751059703, 'min_child_samples': 42}. Best is trial 22 with value: 0.95937876707069.\n",
      "[I 2025-05-17 15:38:27,452] Trial 26 finished with value: 0.9588944687422054 and parameters: {'n_estimators': 419, 'learning_rate': 0.07716146955244282, 'max_depth': 5, 'num_leaves': 26, 'subsample': 0.9633997934816615, 'colsample_bytree': 0.727786147583773, 'min_child_samples': 19}. Best is trial 22 with value: 0.95937876707069.\n",
      "[I 2025-05-17 15:38:28,300] Trial 27 finished with value: 0.9592368498910321 and parameters: {'n_estimators': 373, 'learning_rate': 0.0922714933524707, 'max_depth': 4, 'num_leaves': 23, 'subsample': 0.9301820757426909, 'colsample_bytree': 0.7633971261304218, 'min_child_samples': 29}. Best is trial 22 with value: 0.95937876707069.\n",
      "[I 2025-05-17 15:38:29,596] Trial 28 finished with value: 0.9603306360735137 and parameters: {'n_estimators': 276, 'learning_rate': 0.0826348384072603, 'max_depth': 6, 'num_leaves': 37, 'subsample': 0.9045213629226572, 'colsample_bytree': 0.841062926733509, 'min_child_samples': 48}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:38:30,724] Trial 29 finished with value: 0.9597512401382741 and parameters: {'n_estimators': 269, 'learning_rate': 0.0824255906926777, 'max_depth': 6, 'num_leaves': 37, 'subsample': 0.8698508780174802, 'colsample_bytree': 0.8502757107382387, 'min_child_samples': 47}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:38:31,925] Trial 30 finished with value: 0.9590641562089064 and parameters: {'n_estimators': 259, 'learning_rate': 0.08272478904322601, 'max_depth': 6, 'num_leaves': 46, 'subsample': 0.8679228076836898, 'colsample_bytree': 0.8701308483018828, 'min_child_samples': 48}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:38:32,743] Trial 31 finished with value: 0.9585992048113733 and parameters: {'n_estimators': 274, 'learning_rate': 0.09377503144520011, 'max_depth': 5, 'num_leaves': 44, 'subsample': 0.815326949501827, 'colsample_bytree': 0.857237106589534, 'min_child_samples': 47}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:38:33,503] Trial 32 finished with value: 0.9574884826231818 and parameters: {'n_estimators': 221, 'learning_rate': 0.0845788249242579, 'max_depth': 5, 'num_leaves': 37, 'subsample': 0.8571009763240222, 'colsample_bytree': 0.9043274980060834, 'min_child_samples': 25}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:38:34,858] Trial 33 finished with value: 0.9591591049931156 and parameters: {'n_estimators': 321, 'learning_rate': 0.07575930278994958, 'max_depth': 6, 'num_leaves': 36, 'subsample': 0.8285568546102846, 'colsample_bytree': 0.836311577963113, 'min_child_samples': 35}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:38:35,573] Trial 34 finished with value: 0.957869944572531 and parameters: {'n_estimators': 182, 'learning_rate': 0.06901870519043031, 'max_depth': 6, 'num_leaves': 30, 'subsample': 0.894936283303544, 'colsample_bytree': 0.9417133304771316, 'min_child_samples': 53}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:38:36,219] Trial 35 finished with value: 0.9572178339414221 and parameters: {'n_estimators': 281, 'learning_rate': 0.07905445464019872, 'max_depth': 4, 'num_leaves': 52, 'subsample': 0.8809445178691314, 'colsample_bytree': 0.8155877115340541, 'min_child_samples': 15}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:38:36,975] Trial 36 finished with value: 0.9572169410061476 and parameters: {'n_estimators': 221, 'learning_rate': 0.09480808408354077, 'max_depth': 6, 'num_leaves': 59, 'subsample': 0.9438073030510021, 'colsample_bytree': 0.9858460637742426, 'min_child_samples': 65}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:38:38,139] Trial 37 finished with value: 0.9588065741466664 and parameters: {'n_estimators': 250, 'learning_rate': 0.07391590267391039, 'max_depth': 7, 'num_leaves': 37, 'subsample': 0.9021380609442746, 'colsample_bytree': 0.8896943704664959, 'min_child_samples': 42}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:38:39,050] Trial 38 finished with value: 0.9587934479981283 and parameters: {'n_estimators': 301, 'learning_rate': 0.08557480892090086, 'max_depth': 5, 'num_leaves': 43, 'subsample': 0.7707727378911732, 'colsample_bytree': 0.8569120037013102, 'min_child_samples': 27}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:38:39,608] Trial 39 finished with value: 0.9429374475028469 and parameters: {'n_estimators': 171, 'learning_rate': 0.02075599938227147, 'max_depth': 6, 'num_leaves': 18, 'subsample': 0.9813468492122384, 'colsample_bytree': 0.8386351626450449, 'min_child_samples': 36}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:38:40,988] Trial 40 finished with value: 0.958412343222889 and parameters: {'n_estimators': 362, 'learning_rate': 0.06376977207881572, 'max_depth': 7, 'num_leaves': 49, 'subsample': 0.955981015095218, 'colsample_bytree': 0.9203168858953821, 'min_child_samples': 24}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:38:42,098] Trial 41 finished with value: 0.9596695067961305 and parameters: {'n_estimators': 332, 'learning_rate': 0.07113306903651415, 'max_depth': 6, 'num_leaves': 24, 'subsample': 0.9043882987890828, 'colsample_bytree': 0.7293686386493647, 'min_child_samples': 52}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:38:42,833] Trial 42 finished with value: 0.9583466529511809 and parameters: {'n_estimators': 324, 'learning_rate': 0.08041288809119151, 'max_depth': 6, 'num_leaves': 24, 'subsample': 0.9295791822606616, 'colsample_bytree': 0.7871622141373805, 'min_child_samples': 61}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:38:43,747] Trial 43 finished with value: 0.9583140905781637 and parameters: {'n_estimators': 275, 'learning_rate': 0.07263737335856248, 'max_depth': 5, 'num_leaves': 29, 'subsample': 0.8310976609962953, 'colsample_bytree': 0.7236851107181129, 'min_child_samples': 50}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:38:44,518] Trial 44 finished with value: 0.9592171160214613 and parameters: {'n_estimators': 396, 'learning_rate': 0.08783155243015411, 'max_depth': 7, 'num_leaves': 19, 'subsample': 0.8880249083953153, 'colsample_bytree': 0.746641541393184, 'min_child_samples': 54}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:38:45,160] Trial 45 finished with value: 0.9576112314589432 and parameters: {'n_estimators': 310, 'learning_rate': 0.08120188768372014, 'max_depth': 6, 'num_leaves': 25, 'subsample': 0.9001407560357747, 'colsample_bytree': 0.7143778019819692, 'min_child_samples': 45}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:38:46,513] Trial 46 finished with value: 0.9596040844050044 and parameters: {'n_estimators': 292, 'learning_rate': 0.0638942083076373, 'max_depth': 6, 'num_leaves': 39, 'subsample': 0.9449934859848677, 'colsample_bytree': 0.8181233585297475, 'min_child_samples': 10}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:38:47,602] Trial 47 finished with value: 0.9584849983897401 and parameters: {'n_estimators': 242, 'learning_rate': 0.06470572990424504, 'max_depth': 6, 'num_leaves': 39, 'subsample': 0.9395639058126164, 'colsample_bytree': 0.8234388165458004, 'min_child_samples': 41}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:38:48,990] Trial 48 finished with value: 0.9589156313082158 and parameters: {'n_estimators': 269, 'learning_rate': 0.0534764893621118, 'max_depth': 7, 'num_leaves': 40, 'subsample': 0.9118492293207577, 'colsample_bytree': 0.8735239121762601, 'min_child_samples': 33}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:38:50,260] Trial 49 finished with value: 0.9593560269856946 and parameters: {'n_estimators': 292, 'learning_rate': 0.0707305746214687, 'max_depth': 6, 'num_leaves': 35, 'subsample': 0.8647778040070454, 'colsample_bytree': 0.807334113729334, 'min_child_samples': 11}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:38:51,605] Trial 50 finished with value: 0.9596306343471721 and parameters: {'n_estimators': 335, 'learning_rate': 0.05872424183192727, 'max_depth': 7, 'num_leaves': 30, 'subsample': 0.8832921449479824, 'colsample_bytree': 0.8515045369185087, 'min_child_samples': 81}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:38:52,784] Trial 51 finished with value: 0.9598440458778238 and parameters: {'n_estimators': 331, 'learning_rate': 0.05838437687731539, 'max_depth': 7, 'num_leaves': 31, 'subsample': 0.885447167425407, 'colsample_bytree': 0.848652848670604, 'min_child_samples': 83}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:38:53,731] Trial 52 finished with value: 0.9587346333280351 and parameters: {'n_estimators': 325, 'learning_rate': 0.05877665629729764, 'max_depth': 7, 'num_leaves': 30, 'subsample': 0.8796487884772781, 'colsample_bytree': 0.8536078296647018, 'min_child_samples': 83}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:38:55,215] Trial 53 finished with value: 0.958870032080188 and parameters: {'n_estimators': 291, 'learning_rate': 0.04768992637979401, 'max_depth': 7, 'num_leaves': 42, 'subsample': 0.8428564979249115, 'colsample_bytree': 0.8408743932129374, 'min_child_samples': 94}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:38:56,654] Trial 54 finished with value: 0.9597671939151817 and parameters: {'n_estimators': 335, 'learning_rate': 0.053021842071851254, 'max_depth': 7, 'num_leaves': 32, 'subsample': 0.9050721490680789, 'colsample_bytree': 0.8714522004806768, 'min_child_samples': 80}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:38:58,119] Trial 55 finished with value: 0.9598080605862537 and parameters: {'n_estimators': 339, 'learning_rate': 0.0553103134164721, 'max_depth': 7, 'num_leaves': 33, 'subsample': 0.9039281210327277, 'colsample_bytree': 0.873381474092363, 'min_child_samples': 75}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:38:59,375] Trial 56 finished with value: 0.9593655813931339 and parameters: {'n_estimators': 358, 'learning_rate': 0.054261844032042414, 'max_depth': 7, 'num_leaves': 32, 'subsample': 0.9046820247719497, 'colsample_bytree': 0.8954894518915948, 'min_child_samples': 91}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:39:00,482] Trial 57 finished with value: 0.9573788004069403 and parameters: {'n_estimators': 238, 'learning_rate': 0.0400943777433415, 'max_depth': 7, 'num_leaves': 34, 'subsample': 0.9232095221743133, 'colsample_bytree': 0.8722610784679663, 'min_child_samples': 76}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:39:01,770] Trial 58 finished with value: 0.9587467474832619 and parameters: {'n_estimators': 311, 'learning_rate': 0.0518330011059588, 'max_depth': 7, 'num_leaves': 38, 'subsample': 0.8903463849282989, 'colsample_bytree': 0.87858766933452, 'min_child_samples': 71}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:39:03,285] Trial 59 finished with value: 0.9590124850210108 and parameters: {'n_estimators': 334, 'learning_rate': 0.04570326647799389, 'max_depth': 7, 'num_leaves': 34, 'subsample': 0.8629026428936918, 'colsample_bytree': 0.9146323740066102, 'min_child_samples': 88}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:39:04,128] Trial 60 finished with value: 0.9555341151874599 and parameters: {'n_estimators': 206, 'learning_rate': 0.03890089717281242, 'max_depth': 7, 'num_leaves': 27, 'subsample': 0.8743140541219536, 'colsample_bytree': 0.9367588078580446, 'min_child_samples': 65}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:39:05,540] Trial 61 finished with value: 0.9595221724758058 and parameters: {'n_estimators': 336, 'learning_rate': 0.056518791614129246, 'max_depth': 7, 'num_leaves': 31, 'subsample': 0.9083960142375305, 'colsample_bytree': 0.8615249338827429, 'min_child_samples': 80}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:39:06,447] Trial 62 finished with value: 0.9590603463517344 and parameters: {'n_estimators': 357, 'learning_rate': 0.06107241074680958, 'max_depth': 7, 'num_leaves': 29, 'subsample': 0.8839275471842073, 'colsample_bytree': 0.850065984376302, 'min_child_samples': 83}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:39:07,647] Trial 63 finished with value: 0.9571985465394889 and parameters: {'n_estimators': 338, 'learning_rate': 0.04152334361459295, 'max_depth': 7, 'num_leaves': 35, 'subsample': 0.8946263386437989, 'colsample_bytree': 0.8652504386113119, 'min_child_samples': 78}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:39:08,889] Trial 64 finished with value: 0.9593554316955115 and parameters: {'n_estimators': 306, 'learning_rate': 0.06717777035355328, 'max_depth': 7, 'num_leaves': 33, 'subsample': 0.923493932225505, 'colsample_bytree': 0.8847560838780983, 'min_child_samples': 58}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:39:10,385] Trial 65 finished with value: 0.9594084720508282 and parameters: {'n_estimators': 386, 'learning_rate': 0.05042392171737951, 'max_depth': 7, 'num_leaves': 28, 'subsample': 0.8562009309332332, 'colsample_bytree': 0.8446457953181801, 'min_child_samples': 98}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:39:11,822] Trial 66 finished with value: 0.9593888870038032 and parameters: {'n_estimators': 372, 'learning_rate': 0.06041443153649853, 'max_depth': 6, 'num_leaves': 31, 'subsample': 0.9112501690511654, 'colsample_bytree': 0.8300403593719364, 'min_child_samples': 71}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:39:13,130] Trial 67 finished with value: 0.9567490726867172 and parameters: {'n_estimators': 263, 'learning_rate': 0.03368871950902084, 'max_depth': 7, 'num_leaves': 37, 'subsample': 0.8420490751167639, 'colsample_bytree': 0.96775966281244, 'min_child_samples': 87}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:39:14,602] Trial 68 finished with value: 0.9591519615109179 and parameters: {'n_estimators': 406, 'learning_rate': 0.05668693841071604, 'max_depth': 7, 'num_leaves': 25, 'subsample': 0.8743984030901408, 'colsample_bytree': 0.8991753821551556, 'min_child_samples': 74}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:39:15,806] Trial 69 finished with value: 0.9590344512287682 and parameters: {'n_estimators': 344, 'learning_rate': 0.06755131390263314, 'max_depth': 6, 'num_leaves': 41, 'subsample': 0.8978382688242631, 'colsample_bytree': 0.847492158199597, 'min_child_samples': 52}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:39:16,944] Trial 70 finished with value: 0.9565364052687944 and parameters: {'n_estimators': 320, 'learning_rate': 0.04446155579016599, 'max_depth': 6, 'num_leaves': 36, 'subsample': 0.8882840183294085, 'colsample_bytree': 0.8834889564845734, 'min_child_samples': 65}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:39:17,687] Trial 71 finished with value: 0.9562773052165874 and parameters: {'n_estimators': 286, 'learning_rate': 0.06516242877425299, 'max_depth': 6, 'num_leaves': 39, 'subsample': 0.7030717222614457, 'colsample_bytree': 0.825596385816771, 'min_child_samples': 81}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:39:18,858] Trial 72 finished with value: 0.9586734672617186 and parameters: {'n_estimators': 297, 'learning_rate': 0.06174275313153619, 'max_depth': 6, 'num_leaves': 32, 'subsample': 0.9524653673395299, 'colsample_bytree': 0.8123921817344582, 'min_child_samples': 86}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:39:19,644] Trial 73 finished with value: 0.9572670049105487 and parameters: {'n_estimators': 334, 'learning_rate': 0.07071338919436387, 'max_depth': 6, 'num_leaves': 38, 'subsample': 0.9340623719362621, 'colsample_bytree': 0.8634934468833333, 'min_child_samples': 90}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:39:20,449] Trial 74 finished with value: 0.9562008104280553 and parameters: {'n_estimators': 363, 'learning_rate': 0.05887172650708001, 'max_depth': 6, 'num_leaves': 34, 'subsample': 0.9188754689146384, 'colsample_bytree': 0.8020242591982155, 'min_child_samples': 68}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:39:21,376] Trial 75 finished with value: 0.9582605144616821 and parameters: {'n_estimators': 280, 'learning_rate': 0.053339498465701685, 'max_depth': 7, 'num_leaves': 21, 'subsample': 0.8679285905085424, 'colsample_bytree': 0.831650439319145, 'min_child_samples': 57}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:39:22,298] Trial 76 finished with value: 0.9583991575453329 and parameters: {'n_estimators': 315, 'learning_rate': 0.07406397492934247, 'max_depth': 6, 'num_leaves': 36, 'subsample': 0.9071308111263631, 'colsample_bytree': 0.8507882404256151, 'min_child_samples': 78}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:39:22,815] Trial 77 finished with value: 0.9491641828183777 and parameters: {'n_estimators': 300, 'learning_rate': 0.05512477942535713, 'max_depth': 3, 'num_leaves': 30, 'subsample': 0.8802512147651875, 'colsample_bytree': 0.8672172699669677, 'min_child_samples': 83}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:39:23,669] Trial 78 finished with value: 0.9592894437787117 and parameters: {'n_estimators': 258, 'learning_rate': 0.08388576369383113, 'max_depth': 7, 'num_leaves': 45, 'subsample': 0.9481494973240867, 'colsample_bytree': 0.7916774653028104, 'min_child_samples': 45}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:39:24,570] Trial 79 finished with value: 0.9577232353068988 and parameters: {'n_estimators': 351, 'learning_rate': 0.06559436360431736, 'max_depth': 6, 'num_leaves': 27, 'subsample': 0.9711589764591398, 'colsample_bytree': 0.8379612209449995, 'min_child_samples': 39}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:39:26,000] Trial 80 finished with value: 0.9596120612934584 and parameters: {'n_estimators': 327, 'learning_rate': 0.06277038148512566, 'max_depth': 7, 'num_leaves': 33, 'subsample': 0.8547176945626167, 'colsample_bytree': 0.8178786372647651, 'min_child_samples': 61}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:39:27,098] Trial 81 finished with value: 0.9589614091232983 and parameters: {'n_estimators': 332, 'learning_rate': 0.06240912740277186, 'max_depth': 7, 'num_leaves': 33, 'subsample': 0.8530533584947991, 'colsample_bytree': 0.8191204902823628, 'min_child_samples': 50}. Best is trial 28 with value: 0.9603306360735137.\n",
      "[I 2025-05-17 15:39:28,564] Trial 82 finished with value: 0.9603392082521507 and parameters: {'n_estimators': 328, 'learning_rate': 0.05898539396883614, 'max_depth': 7, 'num_leaves': 35, 'subsample': 0.8451598422673441, 'colsample_bytree': 0.7793409985335162, 'min_child_samples': 62}. Best is trial 82 with value: 0.9603392082521507.\n",
      "[I 2025-05-17 15:39:29,786] Trial 83 finished with value: 0.959244410076358 and parameters: {'n_estimators': 346, 'learning_rate': 0.05855103342322347, 'max_depth': 7, 'num_leaves': 35, 'subsample': 0.8118639640043358, 'colsample_bytree': 0.7693513472339856, 'min_child_samples': 61}. Best is trial 82 with value: 0.9603392082521507.\n",
      "[I 2025-05-17 15:39:31,168] Trial 84 finished with value: 0.9590297484363215 and parameters: {'n_estimators': 327, 'learning_rate': 0.05260458373480195, 'max_depth': 7, 'num_leaves': 29, 'subsample': 0.825638221317229, 'colsample_bytree': 0.8762333481910453, 'min_child_samples': 69}. Best is trial 82 with value: 0.9603392082521507.\n",
      "[I 2025-05-17 15:39:32,260] Trial 85 finished with value: 0.9582473883131442 and parameters: {'n_estimators': 369, 'learning_rate': 0.04760565887387281, 'max_depth': 7, 'num_leaves': 31, 'subsample': 0.8363739701391063, 'colsample_bytree': 0.8447435124083248, 'min_child_samples': 55}. Best is trial 82 with value: 0.9603392082521507.\n",
      "[I 2025-05-17 15:39:33,627] Trial 86 finished with value: 0.9598396407304687 and parameters: {'n_estimators': 307, 'learning_rate': 0.056125498155166334, 'max_depth': 7, 'num_leaves': 32, 'subsample': 0.8599891677079557, 'colsample_bytree': 0.7024667402771625, 'min_child_samples': 63}. Best is trial 82 with value: 0.9603392082521507.\n",
      "[I 2025-05-17 15:39:34,899] Trial 87 finished with value: 0.9590664778406205 and parameters: {'n_estimators': 313, 'learning_rate': 0.05032636699616126, 'max_depth': 7, 'num_leaves': 26, 'subsample': 0.8684700827786125, 'colsample_bytree': 0.7121978221782569, 'min_child_samples': 46}. Best is trial 82 with value: 0.9603392082521507.\n",
      "[I 2025-05-17 15:39:35,916] Trial 88 finished with value: 0.959787195665335 and parameters: {'n_estimators': 385, 'learning_rate': 0.07942788967382362, 'max_depth': 7, 'num_leaves': 32, 'subsample': 0.9002272006178622, 'colsample_bytree': 0.7183673672402734, 'min_child_samples': 74}. Best is trial 82 with value: 0.9603392082521507.\n",
      "[I 2025-05-17 15:39:36,702] Trial 89 finished with value: 0.9585657197385723 and parameters: {'n_estimators': 426, 'learning_rate': 0.0788073007878394, 'max_depth': 7, 'num_leaves': 37, 'subsample': 0.9023955598308548, 'colsample_bytree': 0.7178901022873051, 'min_child_samples': 74}. Best is trial 82 with value: 0.9603392082521507.\n",
      "[I 2025-05-17 15:39:37,633] Trial 90 finished with value: 0.9587510335725805 and parameters: {'n_estimators': 380, 'learning_rate': 0.08308995496373241, 'max_depth': 7, 'num_leaves': 35, 'subsample': 0.8468138333755492, 'colsample_bytree': 0.7008635150635165, 'min_child_samples': 67}. Best is trial 82 with value: 0.9603392082521507.\n",
      "[I 2025-05-17 15:39:38,753] Trial 91 finished with value: 0.9601944336796137 and parameters: {'n_estimators': 285, 'learning_rate': 0.08808066530946107, 'max_depth': 7, 'num_leaves': 32, 'subsample': 0.8936577610281315, 'colsample_bytree': 0.7288974944711184, 'min_child_samples': 63}. Best is trial 82 with value: 0.9603392082521507.\n",
      "[I 2025-05-17 15:39:39,761] Trial 92 finished with value: 0.9594947295983636 and parameters: {'n_estimators': 235, 'learning_rate': 0.08660152635372984, 'max_depth': 7, 'num_leaves': 33, 'subsample': 0.8941040397043533, 'colsample_bytree': 0.7351400620118982, 'min_child_samples': 56}. Best is trial 82 with value: 0.9603392082521507.\n",
      "[I 2025-05-17 15:39:40,463] Trial 93 finished with value: 0.9592092581910443 and parameters: {'n_estimators': 281, 'learning_rate': 0.09138739659319767, 'max_depth': 7, 'num_leaves': 32, 'subsample': 0.9155231716503236, 'colsample_bytree': 0.7449825273955543, 'min_child_samples': 50}. Best is trial 82 with value: 0.9603392082521507.\n",
      "[I 2025-05-17 15:39:41,408] Trial 94 finished with value: 0.9596799243743351 and parameters: {'n_estimators': 268, 'learning_rate': 0.08775910211760805, 'max_depth': 7, 'num_leaves': 38, 'subsample': 0.8627040654254229, 'colsample_bytree': 0.7603342918435478, 'min_child_samples': 59}. Best is trial 82 with value: 0.9603392082521507.\n",
      "[I 2025-05-17 15:39:42,455] Trial 95 finished with value: 0.9594505590667755 and parameters: {'n_estimators': 271, 'learning_rate': 0.09756076918252092, 'max_depth': 7, 'num_leaves': 41, 'subsample': 0.8618360257770115, 'colsample_bytree': 0.7017924057177113, 'min_child_samples': 63}. Best is trial 82 with value: 0.9603392082521507.\n",
      "[I 2025-05-17 15:39:43,620] Trial 96 finished with value: 0.9599526863362448 and parameters: {'n_estimators': 249, 'learning_rate': 0.0884402767187172, 'max_depth': 7, 'num_leaves': 36, 'subsample': 0.8780152005618025, 'colsample_bytree': 0.7537142549606834, 'min_child_samples': 59}. Best is trial 82 with value: 0.9603392082521507.\n",
      "[I 2025-05-17 15:39:44,693] Trial 97 finished with value: 0.9593225716774028 and parameters: {'n_estimators': 255, 'learning_rate': 0.08156310393227141, 'max_depth': 7, 'num_leaves': 36, 'subsample': 0.8770017450934081, 'colsample_bytree': 0.7500878908355083, 'min_child_samples': 64}. Best is trial 82 with value: 0.9603392082521507.\n",
      "[I 2025-05-17 15:39:45,698] Trial 98 finished with value: 0.9600289430087037 and parameters: {'n_estimators': 249, 'learning_rate': 0.09326471153944227, 'max_depth': 7, 'num_leaves': 31, 'subsample': 0.870992645207878, 'colsample_bytree': 0.7784325393539666, 'min_child_samples': 74}. Best is trial 82 with value: 0.9603392082521507.\n",
      "[I 2025-05-17 15:39:46,612] Trial 99 finished with value: 0.9596754596979616 and parameters: {'n_estimators': 225, 'learning_rate': 0.09561702925698749, 'max_depth': 7, 'num_leaves': 31, 'subsample': 0.8917113529164712, 'colsample_bytree': 0.7831175004550671, 'min_child_samples': 73}. Best is trial 82 with value: 0.9603392082521507.\n"
     ]
    }
   ],
   "source": [
    "# LightGBM Tuning\n",
    "study_lgbm = optuna.create_study(direction=\"maximize\")\n",
    "study_lgbm.optimize(objective_lgbm, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Best Scores and Parameters\n",
    "\n",
    "\n",
    "After running Optuna, we extract and display the best AUC score of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LightGBM Best AUC: 0.9603392082521507\n"
     ]
    }
   ],
   "source": [
    "print(\"LightGBM Best AUC:\", study_lgbm.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Retrain and Evaluate\n",
    "\n",
    "\n",
    "We retrain the model using the best-found parameters and evaluate final AUC-ROC performance on the hold-out test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-train Best LightGBM Model On Full Training Data \n",
    "best_lgbm_model = LGBMClassifier(\n",
    "    **study_lgbm.best_params,\n",
    "    random_state=42\n",
    ")\n",
    "best_lgbm_model.fit(X_train_lgbm, y_train_lgbm)\n",
    "lgbm_probs = best_lgbm_model.predict_proba(X_test_lgbm)[:, 1]\n",
    "lgbm_auc_final = roc_auc_score(y_test_lgbm, lgbm_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary of Results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final LightGBM AUC on Test Set: 0.9603392082521507\n"
     ]
    }
   ],
   "source": [
    "print(\"Final LightGBM AUC on Test Set:\", lgbm_auc_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning improved performance over the baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: SHAP-Based Feature Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. SHAP Introduction\n",
    "\n",
    "In this section, we use SHAP values to interpret and rank feature importance for LightGBM. We then retrain the model using only the most impactful features and evaluate whether this improves AUC-ROC on the test set.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Compute SHAP Values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasgarzon/Codes/Loan Approval Prediction/.venv/lib/python3.12/site-packages/shap/explainers/_tree.py:583: UserWarning: LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# LightGBM SHAP Values\n",
    "explainer_lgbm = shap.TreeExplainer(best_lgbm_model)\n",
    "shap_values_lgbm = explainer_lgbm.shap_values(X_train_lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Calculate SHAP Importances\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM SHAP Importance\n",
    "shap_importance_lgbm = pd.DataFrame({\n",
    "    \"feature\": X_train_lgbm.columns,\n",
    "    \"importance\": np.abs(shap_values_lgbm).mean(axis=0)\n",
    "}).sort_values(\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Select Top Features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM Top Features\n",
    "top_features_lgbm = shap_importance_lgbm[shap_importance_lgbm[\"importance\"] > 0.001][\"feature\"].tolist()\n",
    "X_train_lgbm_reduced = X_train_lgbm[top_features_lgbm]\n",
    "X_test_lgbm_reduced = X_test_lgbm[top_features_lgbm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Retrain and Evaluate with SHAP Features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM Re-Training\n",
    "model_lgbm_reduced = LGBMClassifier(**study_lgbm.best_params, random_state=42)\n",
    "model_lgbm_reduced.fit(X_train_lgbm_reduced, y_train_lgbm)\n",
    "\n",
    "lgbm_probs = model_lgbm_reduced.predict_proba(X_test_lgbm_reduced)[:, 1]\n",
    "lgbm_auc_shap = roc_auc_score(y_test_lgbm, lgbm_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Summary of SHAP Results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LightGBM AUC after SHAP-based feature selection: 0.9597482636873584\n"
     ]
    }
   ],
   "source": [
    "print(\"LightGBM AUC after SHAP-based feature selection:\", lgbm_auc_shap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP-based feature selection did not improve performance beyond the tuned model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Interpretation and Insights\n",
    "\n",
    "- **Model selection rationale**: LightGBM outperformed other models across all stages, achieving a best validation AUC of **0.9603** and maintaining that performance on the test set. Even after SHAP-based feature selection, the AUC remained strong at **0.9597**, confirming model stability.\n",
    "\n",
    "- **Improvement through tuning**: Performance gains were observed after tuning of hyperparameters, validating the effectiveness of Optuna in our workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/input_columns.pkl']"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the Best Model\n",
    "joblib.dump(best_lgbm_model, \"models/best_lightgbm_model.pkl\")\n",
    "\n",
    "# Save Input Feature Columns Used For Training\n",
    "input_cols = X_train_lgbm.columns.tolist()\n",
    "joblib.dump(input_cols, \"models/input_columns.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
